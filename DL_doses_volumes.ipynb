{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.nn.functional import grid_sample\n",
    "import nibabel as nib\n",
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import zoom\n",
    "#from models.densenet import DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "3939\n"
     ]
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "#Path to data\n",
    "path_to_data = \"G:\\data\\dose_matrices_updated_25_01_2023\"\n",
    "print(len(os.listdir(join(path_to_data, \"nii\"))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 67, 70, 71)\n"
     ]
    }
   ],
   "source": [
    "image = np.squeeze(np.asanyarray(nib.load('G:/data/dose_matrices_updated_25_01_2023/nii/newdosi_3_197708498_ID2013A.nii.gz').dataobj))[np.newaxis]\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "image_cropped = image[0:1,2:66, 3:67, 3:67]\n",
    "print(image_cropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, annotations_file, path_to_dir, min_card_age, \n",
    "               training=False, validation=False, transform=None, target_transform=None):\n",
    "    \n",
    "    assert min_card_age == 40 or min_card_age == 50\n",
    "\n",
    "    labels_csv = pd.read_csv(join(path_to_dir, annotations_file), sep=',')\n",
    "\n",
    "    if training:\n",
    "      self.img_labels = labels_csv[labels_csv[f'train_{min_card_age}'] == 1]\n",
    "    elif validation:\n",
    "      self.img_labels = labels_csv[labels_csv[f'val_{min_card_age}'] == 1]\n",
    "\n",
    "    self.path_to_dir = path_to_dir\n",
    "    self.img_dir = join(self.path_to_dir, 'nii')\n",
    "\n",
    "    self.transform = transform\n",
    "    self.target_transform = target_transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.img_labels)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx][\"file_name\"])\n",
    "    image = np.squeeze(np.asanyarray(nib.load(img_path).dataobj))[np.newaxis]\n",
    "    image_cropped = image[0:1,2:66, 3:67, 3:67]\n",
    "\n",
    "    label = self.img_labels.iloc[idx]['Pathologie_cardiaque_3_new']\n",
    "\n",
    "    if self.transform:\n",
    "        image = self.transform(image)\n",
    "    if self.target_transform:\n",
    "        label = self.target_transform(label)\n",
    "\n",
    "    return image_cropped, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "723 181\n",
      "done\n",
      "torch.Size([4, 1, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "training_data = CustomDataset(\"labels.csv\", path_to_data, 40, training = True)\n",
    "val_data = CustomDataset(\"labels.csv\", path_to_data, 40, validation = True)\n",
    "\n",
    "print(len(training_data), len(val_data))\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size, shuffle=True)\n",
    "print('done')\n",
    "\n",
    "input, label = next(iter(val_dataloader))\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1er modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, batch_size, hidden_units=200):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(batch_size*64*64*64, hidden_units)\n",
    "        self.fc2 = nn.Linear(hidden_units, hidden_units)\n",
    "        self.fc3 = nn.Linear(hidden_units, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc3(x)\n",
    "        return x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_our_model(val_dataloader, model):  # no arguments, literally all our variable our globals (not great but it's a notebook)\n",
    "    # Put model in eval mode\n",
    "    model.eval()  # to remove stuff like dropout that's only going to be in the training part\n",
    "\n",
    "    # Setup test accuracy value\n",
    "    test_acc = 0\n",
    "\n",
    "    # Turn on inference context manager\n",
    "    with torch.no_grad():\n",
    "        # Loop through DataLoader batches\n",
    "        for X_test, y_test in val_dataloader:  # majuscule à X car c'est une \"matrice\", et y un entier\n",
    "            # 1. Forward pass\n",
    "            # print(X_test.view(-1, 64*64*3).shape)\n",
    "            # break\n",
    "            X_flatten = X_test.flatten()\n",
    "            model_output = model(X_flatten.float())\n",
    "\n",
    "            # 2. Calculate and accumulate accuracy\n",
    "            test_pred_label = model_output.argmax()\n",
    "            test_acc += (test_pred_label == y_test).sum()  # True == 1, False == 0\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch\n",
    "    test_acc = test_acc / (val_dataloader.batch_size*len(val_dataloader))\n",
    "    print(test_acc.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(4,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's begin\n",
      "0.6944444179534912\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's begin\")\n",
    "test_our_model(val_dataloader, model.float())  #ça marche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer_adam = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "optimizer_sgd = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "nbr_epochs: int = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optimizer):\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "\n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for epoch in tqdm(range(nbr_epochs)):\n",
    "        # Loop through data loader data batches\n",
    "        for i, value in enumerate(train_dataloader):\n",
    "\n",
    "            X, y = value[0], value[1]\n",
    "            print(X.shape)\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            X_flatten = X.flatten()\n",
    "            X_flatten = X_flatten.float()\n",
    "            y_pred = model(X_flatten.float())\n",
    "        \n",
    "            print(y)\n",
    "            print(y_pred)\n",
    "\n",
    "            # 2. Calculate  and accumulate loss\n",
    "            loss = loss_fn(y_pred.float(), y.float())\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # 3. Optimizer zero grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 4. Loss backward\n",
    "            loss.backward()\n",
    "\n",
    "            # 5. Optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate and accumulate accuracy metric across all batches\n",
    "            y_pred_class = y_pred.argmax()\n",
    "            train_acc += (y_pred_class == y).sum()\n",
    "\n",
    "        # Adjust metrics to get average loss and accuracy per batch\n",
    "        train_loss = train_loss / (train_dataloader.batch_size * len(train_dataloader))\n",
    "        train_acc = train_acc / (train_dataloader.batch_size * len(train_dataloader))\n",
    "        print(\n",
    "            f\"epoch {epoch+1}/{nbr_epochs},\"\n",
    "            f\" train_loss = {train_loss:.2e},\"\n",
    "            f\" train_acc = {100*train_acc.item():.2f}%\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 64, 64])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([-0.0137,  0.0893], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch (got input: [2], target: [4])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-56c67eb7660b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_adam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-1c7409e5c8b2>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(optimizer)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m# 2. Calculate  and accumulate loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1174\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3024\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3025\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3026\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch (got input: [2], target: [4])"
     ]
    }
   ],
   "source": [
    "train(optimizer_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's check\n",
      "0.9777777791023254\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's check\")\n",
    "test_our_model(val_dataloader, model.float())  #ça marche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "print(training_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_test(nn.Module):\n",
    "    def __init__(self, out_channel):\n",
    "        super(CNN_test, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            #conv layer 1\n",
    "            nn.Conv3d(1,out_channel, kernel_size=(3,3,3), padding=1),\n",
    "            #nn.BatchNorm3d(out_channel),\n",
    "            nn.ReLU())\n",
    "            #nn.MaxPool3d((2,2,2)),\n",
    "\n",
    "            #conv Layer 2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(out_channel,out_channel*2,kernel_size=(3,3,3), padding=1),\n",
    "            nn.BatchNorm3d(out_channel*2),\n",
    "            nn.ReLU())\n",
    "            #nn.MaxPool3d((2,2,2)),\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv3d(out_channel*2, out_channel*3, kernel_size=(3,3,3), padding=1),\n",
    "            nn.BatchNorm3d(out_channel*3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(64*14*14, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 2)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(-1, 64*64*64*4)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "nbr_epochs = 5\n",
    "\n",
    "model = CNN_test(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4177031aecad415288a3ea7828386a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 64, 64])\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [4, 1, 3, 3, 3], expected input[1, 4, 64, 64, 64] to have 1 channels, but got 4 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-fe75b5682ddd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain_train_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-73-6022a2ae4692>\u001b[0m in \u001b[0;36mmain_train_conv\u001b[1;34m(loss_fn, optimizer)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;31m# 2. Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m# 3. Calculate and accumulate loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-84-e781be29097c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 613\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    607\u001b[0m             )\n\u001b[0;32m    608\u001b[0m         return F.conv3d(\n\u001b[1;32m--> 609\u001b[1;33m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    610\u001b[0m         )\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [4, 1, 3, 3, 3], expected input[1, 4, 64, 64, 64] to have 1 channels, but got 4 channels instead"
     ]
    }
   ],
   "source": [
    "main_train_conv(nn.CrossEntropyLoss(), torch.optim.Adam(model.parameters(), lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    \n",
    "        self.conv_layer1 = nn.Conv3d(2,4,kernel_size=3)\n",
    "        self.pool = nn.MaxPool3d(4,3)\n",
    "        self.conv_layer2 = nn.Conv3d(4,16,kernel_size=3)\n",
    "        self.linear_layer1 = nn.Linear(2000, 100)\n",
    "        self.linear_layer2 = nn.Linear(100,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1,2000)\n",
    "        x = F.relu(self.linear_layer1(x))\n",
    "        x = F.relu(self.linear_layer2(x))\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train_conv(loss_fn, optimizer) -> None:\n",
    "    \"\"\"\n",
    "    Train the model and modified the trained model inplace.\n",
    "    \"\"\"\n",
    "    start_time_global = time.time()\n",
    "\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "\n",
    "    # Loop through data loader data batches\n",
    "    for epoch in tqdm(range(5)):\n",
    "        start_time_epoch = time.time()\n",
    "\n",
    "        # Setup train loss and train accuracy values\n",
    "        train_loss, train_acc = 0, 0\n",
    "\n",
    "        for X, y in train_dataloader:\n",
    "\n",
    "            # 2. Forward pass\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # 3. Calculate and accumulate loss\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # 4. Optimizer zero grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 5. Loss backward\n",
    "            loss.backward()\n",
    "\n",
    "            # 6. Optimizer step\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate and accumulate accuracy metric across all batches\n",
    "            y_pred_class = y_pred.argmax(dim=1)\n",
    "            train_acc += (y_pred_class == y).sum()\n",
    "\n",
    "        \n",
    "\n",
    "        # Adjust metrics to get average loss and accuracy per batch\n",
    "        train_loss = train_loss / (batch_size * len(train_dataloader))\n",
    "        train_acc = train_acc / (batch_size * len(train_dataloader))\n",
    "        \n",
    "        print(\n",
    "            f\"epoch {epoch+1}/{10},\"\n",
    "            f\" train_loss = {train_loss:.2e},\"\n",
    "            f\" train_acc = {100*train_acc.item():.2f}%,\"\n",
    "            f\" time spent during this epoch = {time.time() - start_time_epoch:.2f}s,\"\n",
    "            f\" total time spent = {time.time() - start_time_global:.2f}s\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8aadab7d8c04e3286f50bca253b3181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [12, 1, 3, 3, 3], expected input[1, 4, 64, 64, 64] to have 1 channels, but got 4 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-fe75b5682ddd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain_train_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-e8e471a912cf>\u001b[0m in \u001b[0;36mmain_train_conv\u001b[1;34m(loss_fn, optimizer)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m# 2. Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m# 3. Calculate and accumulate loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-8cf35aad0606>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 613\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    607\u001b[0m             )\n\u001b[0;32m    608\u001b[0m         return F.conv3d(\n\u001b[1;32m--> 609\u001b[1;33m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    610\u001b[0m         )\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [12, 1, 3, 3, 3], expected input[1, 4, 64, 64, 64] to have 1 channels, but got 4 channels instead"
     ]
    }
   ],
   "source": [
    "main_train_conv(nn.CrossEntropyLoss(), torch.optim.Adam(model.parameters(), lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracyFUNCTION (Predicted, Targets):          \n",
    "    C=0\n",
    "    for I in range(len(Targets)):\n",
    "        if (Predicted[I] == Targets[I]):\n",
    "            C+=1\n",
    "    Accuracy =  C / float(len(Targets))\n",
    "    print('Accuracy   = ', C ,'/', len(Targets))\n",
    "    return(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([2])) must be the same as input size (torch.Size([1]))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-c35b90a9eb38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# Update parameters using SGD optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    721\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m                                                   reduction=self.reduction)\n\u001b[0m\u001b[0;32m    724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   3158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3159\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3160\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3162\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Target size (torch.Size([2])) must be the same as input size (torch.Size([1]))"
     ]
    }
   ],
   "source": [
    "itr = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "for epoch in range(nbr_epochs):\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_dataloader):\n",
    "        labels = Variable(labels.type(dtype=torch.float32))\n",
    "        \n",
    "        train = Variable(images.type(dtype=torch.float32).view(2,64,64,64))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(train)\n",
    "\n",
    "        outputs = outputs.type(dtype=torch.float32).view(-1)\n",
    "\n",
    "\n",
    "        loss = criterion(outputs, labels.view(-1))\n",
    "        loss.backward()\n",
    "        # Update parameters using SGD optimizer \n",
    "        optimizer.step()\n",
    "\n",
    "        #calculate the accuracy using test data\n",
    "        itr += 1\n",
    "        if itr % 100 == 0:\n",
    "            # Prepare a list of correct results and a list of anticipated results.     \n",
    "            listLabels=[]\n",
    "            listpredicted=[]\n",
    "            # test_loader\n",
    "            for images, labels in val_dataloader:\n",
    "\n",
    "                test = Variable(images.type(dtype=torch.float32).view(2,64,64,64))\n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                outputs = outputs.type(dtype=torch.float32).view(-1)\n",
    "                \n",
    "                # used to convert the output to binary variables\n",
    "                #predicted= one_hit_data(outputs) \n",
    "\n",
    "                # Create a list of predicted data\n",
    "                predlist=[]\n",
    "                for i in range(len(outputs)):\n",
    "                    p = int(torch.argmax(outputs[i]))\n",
    "                    predlist.append(p)\n",
    "\n",
    "                \n",
    "                listLabels+=(labels.tolist())\n",
    "                listpredicted+=(predlist)\n",
    "\n",
    "                \n",
    "                # calculate Accuracy\n",
    "            accuracy= accuracyFUNCTION(listpredicted, listLabels)\n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(itr, loss.data, accuracy))\n",
    "\n",
    "            # store loss and accuracy. They'll be required to print the curve.\n",
    "            loss_list.append(loss.data)\n",
    "            accuracy_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0.])\n",
      "['0', '0']\n",
      "tensor([0., 0.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictionlist=[]\n",
    "for i in range(len(outputs)):\n",
    "    p = int(torch.argmax(outputs[i]))\n",
    "    predictionlist.append(p)\n",
    "\n",
    "labels1 = labels.view(-1)\n",
    "print(labels1)\n",
    "#labels1 = [str(x) for x in labels1]\n",
    "predictionlist = [str(x) for x in predictionlist]\n",
    "print(predictionlist)\n",
    "print(labels1)\n",
    "cm = confusion_matrix(labels1, predictionlist, labels = [0,1])\n",
    "\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot = True, ax = ax, cmap = plt.cm.Blues)\n",
    "ax.set_xlabel(\"predicted labels\")\n",
    "ax.set_ylabel(\"true labels\")\n",
    "plt.rcParams['figure.figsize'] = (8,7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictionlist=[]\n",
    "For I In Range(Len(Outputs)):\n",
    "    P = Int(Torch.Argmax(Outputs[I]))\n",
    "    Predictionlist.Append(P)\n",
    "Labels1=Labels.Argmax(-1).Tolist()\n",
    "Labels1= [Str(X) For X In Labels1]\n",
    "Predictionlist= [Str(X) For X In Predictionlist]\n",
    "LabelsLIST = ['0','1', '2','3', '4','5', '6','7', '8','9']\n",
    "Cm = Confusion_matrix(Labels1, Predictionlist, Labels=LabelsLIST)\n",
    "ConfusionMatrixDisplay(Cm).Plot()\n",
    "#   ******************** Color Of Confusion Matrix \n",
    "\n",
    "\n",
    "Ax= Plt.Subplot()\n",
    "Sns.Heatmap(Cm, Annot=True, Ax = Ax, Cmap=Plt.Cm.Blues); #Annot=True To Annotate Cells\n",
    "\n",
    "# Labels, Title And Ticks\n",
    "Ax.Set_xlabel('Predicted Labels');Ax.Set_ylabel('True Labels') \n",
    "Ax.Set_title('Confusion Matrix'); \n",
    "Ax.Xaxis.Set_ticklabels( ['0','1', '2','3', '4','5', '6','7', '8','9']); Ax.Yaxis.Set_ticklabels(['0','1', '2','3', '4','5', '6','7', '8','9'])\n",
    "Plt.RcParams['Figure.Figsize'] = (8, 7)\n",
    "Plt.Show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "a, b = next(iter(train_dataloader))\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, out_channels: int, hidden_units : int =200):\n",
    "        super(CNN, self).__init__()\n",
    "        self.out_channels : int = out_channels\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(1, out_channels, kernel_size=3, stride = 1, padding =1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, stride =1, padding = 1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(out_channels*64*64*64, hidden_units)\n",
    "        self.fc2 = nn.Linear(hidden_units, hidden_units)\n",
    "        self.fc3 = nn.Linear(hidden_units, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(-1, self.out_channels*64*64*64)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (fc1): Linear(in_features=4194304, out_features=200, bias=True)\n",
       "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (fc3): Linear(in_features=200, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = CNN(16)\n",
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train_conv(loss_fn, optimizer) -> None:\n",
    "    \"\"\"\n",
    "    Train the model and modified the trained model inplace.\n",
    "    \"\"\"\n",
    "    start_time_global = time.time()\n",
    "\n",
    "    # Put model in train mode\n",
    "    cnn.train()\n",
    "\n",
    "    # Loop through data loader data batches\n",
    "    for epoch in range(10):\n",
    "        start_time_epoch = time.time()\n",
    "\n",
    "        # Setup train loss and train accuracy values\n",
    "        train_loss, train_acc = 0, 0\n",
    "        pbar = tqdm(train_dataloader)\n",
    "        for X, y in pbar:\n",
    "\n",
    "            # 2. Forward pass\n",
    "            y_pred = cnn(X)\n",
    "\n",
    "            # 3. Calculate and accumulate loss\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # 4. Optimizer zero grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 5. Loss backward\n",
    "            loss.backward()\n",
    "\n",
    "            # 6. Optimizer step\n",
    "            optimizer.step()\n",
    "            pbar.set_description(\"Training batch loss %s\" % loss.item())\n",
    "\n",
    "            # Calculate and accumulate accuracy metric across all batches\n",
    "            y_pred_class = y_pred.argmax(dim=1)\n",
    "            train_acc += (y_pred_class == y).sum()\n",
    "\n",
    "        # Adjust metrics to get average loss and accuracy per batch\n",
    "        train_loss = train_loss / (4 * len(train_dataloader))\n",
    "        train_acc = train_acc / (4 * len(train_dataloader))\n",
    "        print(\n",
    "            f\"epoch {epoch+1}/{10},\"\n",
    "            f\" train_loss = {train_loss:.2e},\"\n",
    "            f\" train_acc = {100*train_acc.item():.2f}%,\"\n",
    "            f\" time spent during this epoch = {time.time() - start_time_epoch:.2f}s,\"\n",
    "            f\" total time spent = {time.time() - start_time_global:.2f}s\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb149185b2a74138af4f372d182be1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=181), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-296-cfc6668f01f5>\", line 1, in <module>\n",
      "    main_train_conv(nn.CrossEntropyLoss(), torch.optim.SGD(cnn.parameters(), lr=0.05))\n",
      "  File \"<ipython-input-295-0ed8d87aab31>\", line 20, in main_train_conv\n",
      "    y_pred = cnn(X)\n",
      "  File \"c:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"<ipython-input-291-b02c2d16a94c>\", line 23, in forward\n",
      "    x = self.conv1(x)\n",
      "  File \"c:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 204, in forward\n",
      "    input = module(input)\n",
      "  File \"c:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\", line 102, in forward\n",
      "    return F.relu(input, inplace=self.inplace)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\Users\\Thomas\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\Users\\Thomas\\Anaconda3\\lib\\inspect.py\", line 1500, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\Users\\Thomas\\Anaconda3\\lib\\inspect.py\", line 1458, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\Users\\Thomas\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\Users\\Thomas\\Anaconda3\\lib\\inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "main_train_conv(nn.CrossEntropyLoss(), torch.optim.SGD(cnn.parameters(), lr=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0db9d80b1ea0552a46577f24f834a8508af16c95b554892edcd696faea0578b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
